{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pycoder-example.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoftept/vjyujqHPbkes/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshu-dutta/pycoder/blob/master/docs/example_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF_eLLLvJDAi",
        "outputId": "c602c5aa-2597-4601-b506-539f4257fb28"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 22 13:44:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4tTXovi1ELE8",
        "outputId": "50ef346a-4efd-498a-97a9-60bec01bed79"
      },
      "source": [
        "!pip install git+https://github.com/himanshu-dutta/pycoder.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/himanshu-dutta/pycoder.git\n",
            "  Cloning https://github.com/himanshu-dutta/pycoder.git to /tmp/pip-req-build-soauxg8p\n",
            "  Running command git clone -q https://github.com/himanshu-dutta/pycoder.git /tmp/pip-req-build-soauxg8p\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typer==0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting fastapi==0.65.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b9/a91a699f5c201413b3f61405dbccc29ebe5ad25945230e9cec98fdb2434c/fastapi-0.65.1-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from pycoder==1.0.2) (1.8.1+cu101)\n",
            "Collecting uvicorn==0.13.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/de/953f0289508b1b92debdf0a6822d9b88ffb0c6ad471d709cf639a2c8a176/uvicorn-0.13.4-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hCollecting transformers==4.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 17.3MB/s \n",
            "\u001b[?25hCollecting click-spinner==0.1.10\n",
            "  Downloading https://files.pythonhosted.org/packages/93/2a/04893832bfeddc2d40a7de2e8153b3085f12d63507d91a9cf0157dc3a1c2/click_spinner-0.1.10-py2.py3-none-any.whl\n",
            "Collecting pygments==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/c9/be11fce9810793676017f79ffab3c6cb18575844a6c7b8d4ed92f95de604/Pygments-2.9.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 32.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from pycoder==1.0.2) (3.3.4)\n",
            "Collecting click<7.2.0,>=7.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n",
            "\u001b[?25hCollecting starlette==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/34/db1890f442a1cd3a2c761f4109a0eb4e63503218d70a8c8e97faa09a5500/starlette-0.14.2-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.8MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->pycoder==1.0.2) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->pycoder==1.0.2) (1.19.5)\n",
            "Collecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder==1.0.2) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder==1.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder==1.0.2) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1->pycoder==1.0.2) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1->pycoder==1.0.2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.1->pycoder==1.0.2) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.1->pycoder==1.0.2) (2.4.7)\n",
            "Building wheels for collected packages: pycoder\n",
            "  Building wheel for pycoder (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycoder: filename=pycoder-1.0.2-cp37-none-any.whl size=19309 sha256=7b65ee4ce5f8b29174032b1c1be747adca89f9818fb88fca1305c9660cd7b375\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k94l8rgs/wheels/03/64/46/d132c267fb8a637bf4e84ce1cfbfe19fc92b357f9d4d3936b7\n",
            "Successfully built pycoder\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: click, typer, starlette, pydantic, fastapi, h11, uvicorn, huggingface-hub, tokenizers, sacremoses, transformers, click-spinner, pygments, pycoder\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "  Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "Successfully installed click-7.1.2 click-spinner-0.1.10 fastapi-0.65.1 h11-0.12.0 huggingface-hub-0.0.8 pycoder-1.0.2 pydantic-1.8.2 pygments-2.9.0 sacremoses-0.0.45 starlette-0.14.2 tokenizers-0.10.2 transformers-4.6.1 typer-0.3.2 uvicorn-0.13.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pygments"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUfUbUSPFdY9",
        "outputId": "f94e6bb8-fe5f-4425-93f3-cc6535bf6027"
      },
      "source": [
        "!pycoder --help"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 12:53:57.670995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Usage: pycoder [OPTIONS]\n",
            "\n",
            "  CLI command to get Python 🐍 code from set of\n",
            "  topic[s] and description. Examples:\n",
            "\n",
            "  🔥 pycoder --topic pytorch --description \"a\n",
            "  trainer for vision\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -d \"a trainer for vision\"\n",
            "\n",
            "  🔥 pycoder --topic pytorch --topic torch\n",
            "  --description \"a trainer for vision\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -t torch -d \"a trainer\n",
            "  for vision\"\n",
            "\n",
            "  🔥 pycoder --topic pytorch --topic torch\n",
            "  --description \"a trainer for vision\" --prefix\n",
            "  \"class Trainer:\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -t torch -d \"a trainer\n",
            "  for vision\" --prefix \"class Trainer:\"\n",
            "\n",
            "Options:\n",
            "  -t, --topic TEXT                topic[s] for the\n",
            "                                  code to be\n",
            "                                  written.\n",
            "                                  [required]\n",
            "\n",
            "  -d, --description TEXT          description of\n",
            "                                  the code to be\n",
            "                                  written.\n",
            "                                  [required]\n",
            "\n",
            "  -p, --prefix TEXT               starting of the\n",
            "                                  code for pycoder\n",
            "                                  to follow.\n",
            "                                  [default: ]\n",
            "\n",
            "  -ml, --max-length INTEGER       max length of\n",
            "                                  code to\n",
            "                                  generate.\n",
            "                                  [default: 200]\n",
            "\n",
            "  -c, --cuda                      if cuda device\n",
            "                                  is to be used\n",
            "                                  for inference or\n",
            "                                  not. Might not\n",
            "                                  work in case\n",
            "                                  VRAM is <4GB.\n",
            "                                  [default: False]\n",
            "\n",
            "  -et, --execution_time           get execution\n",
            "                                  time of\n",
            "                                  generating the\n",
            "                                  code.  [default:\n",
            "                                  False]\n",
            "\n",
            "  -e, --endpoint                  specify the port\n",
            "                                  to start the\n",
            "                                  endpoint on.\n",
            "\n",
            "  -v, --version                   shows the\n",
            "                                  current version\n",
            "                                  of Pycoder.\n",
            "\n",
            "  --install-completion [bash|zsh|fish|powershell|pwsh]\n",
            "                                  Install\n",
            "                                  completion for\n",
            "                                  the specified\n",
            "                                  shell.\n",
            "\n",
            "  --show-completion [bash|zsh|fish|powershell|pwsh]\n",
            "                                  Show completion\n",
            "                                  for the\n",
            "                                  specified shell,\n",
            "                                  to copy it or\n",
            "                                  customize the\n",
            "                                  installation.\n",
            "\n",
            "  --help                          Show this\n",
            "                                  message and\n",
            "                                  exit.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XLbKPGpGjxv",
        "outputId": "3b50c4c9-a053-4bad-f147-6ad62a06e85e"
      },
      "source": [
        "!pycoder --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 12:54:07.784540: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Pycoder 🐍 CLI version: 1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2TioGQuGpw0",
        "outputId": "5d65854e-f78d-4e46-bd94-dd1fdd0c31be"
      },
      "source": [
        "!pycoder -t pytorch -t torch -d \"a trainer class to train vision model\" -ml 1024 -c -et"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 12:55:01.345721: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "-\u001b[32m\n",
            "Model and Tokenizer being downloaded and saved from ModelHub (once only)...\n",
            "\u001b[0;0m\n",
            "Downloading: 100% 943/943 [00:00<00:00, 757kB/s]\n",
            "Downloading: 100% 1.44G/1.44G [01:08<00:00, 21.2MB/s]\n",
            "Downloading: 100% 943/943 [00:00<00:00, 686kB/s]\n",
            "Downloading: 100% 798k/798k [00:00<00:00, 2.44MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.46MB/s]\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 3.47MB/s]\n",
            "Downloading: 100% 90.0/90.0 [00:00<00:00, 65.5kB/s]\n",
            "Downloading: 100% 120/120 [00:00<00:00, 96.1kB/s]\n",
            "Downloading: 100% 207/207 [00:00<00:00, 161kB/s]\n",
            "\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\u001b[32m\u001b[1m\n",
            "Model and Tokenizer saved.\n",
            " ✅\u001b[0;0m\n",
            "\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
            "\n",
            "\u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mstart training\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "\n",
            "\n",
            "device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
            "\n",
            "\n",
            "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mEncoder\u001b[39;49;00m(torch.nn.Module):\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_size, hidden_dim, nbins=\u001b[34m1\u001b[39;49;00m, bottleneck=\u001b[34m1\u001b[39;49;00m):\n",
            "        \u001b[36msuper\u001b[39;49;00m(Encoder, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
            "        \u001b[36mself\u001b[39;49;00m.nbs = nbins\n",
            "        \u001b[36mself\u001b[39;49;00m.bottleneck = bottleneck\n",
            "        \u001b[34mif\u001b[39;49;00m input_size % nbins != \u001b[34m0\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m input_size % nbins == \u001b[34m0\u001b[39;49;00m:\n",
            "            \u001b[34mraise\u001b[39;49;00m \u001b[36mNotImplementedError\u001b[39;49;00m\n",
            "        \u001b[36mself\u001b[39;49;00m.encoder = nn.Sequential(\n",
            "            nn.Linear(input_size, hidden_dim * nbins),\n",
            "            nn.GELU(),\n",
            "            torch.UnflatedLSTM(\n",
            "               in_features=hidden_dim,\n",
            "                out_features=hidden_dim,\n",
            "                kernel_size=\u001b[36mself\u001b[39;49;00m.nbs // bottleneck,\n",
            "                stride=\u001b[36mself\u001b[39;49;00m.bottleneck,\n",
            "            )\n",
            "        )\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
            "        x = \u001b[36mself\u001b[39;49;00m.encoder(x)\n",
            "        x = x / \u001b[36mself\u001b[39;49;00m.nbins - \u001b[34m1\u001b[39;49;00m\n",
            "        \u001b[34mreturn\u001b[39;49;00m x\n",
            "\n",
            "\n",
            "model = Encoder(input_size, hidden_dim, nbins=\u001b[34m9\u001b[39;49;00m, bottleneck=\u001b[33m\"\u001b[39;49;00m\u001b[33m1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "result = model(model)\n",
            "\u001b[36mprint\u001b[39;49;00m(result)\n",
            "\n",
            "\u001b[32m\u001b[1mtook 112.79 seconds to code 😀\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVh6GMvaUITZ"
      },
      "source": [
        "# PyPI Published Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CChYPm2bG0ev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c825e59-9b00-4dd3-9840-d4b21bd9d46c"
      },
      "source": [
        "!pip install pycoder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycoder\n",
            "  Downloading https://files.pythonhosted.org/packages/ce/7a/188358a1f8365f72b477e9ece39e4521f07a7ceaf7c9599f514783026540/pycoder-1.0.2-py3-none-any.whl\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from pycoder) (1.8.1+cu101)\n",
            "Collecting pygments==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/c9/be11fce9810793676017f79ffab3c6cb18575844a6c7b8d4ed92f95de604/Pygments-2.9.0-py3-none-any.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 9.7MB/s \n",
            "\u001b[?25hCollecting click-spinner==0.1.10\n",
            "  Downloading https://files.pythonhosted.org/packages/93/2a/04893832bfeddc2d40a7de2e8153b3085f12d63507d91a9cf0157dc3a1c2/click_spinner-0.1.10-py2.py3-none-any.whl\n",
            "Collecting transformers==4.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 41.6MB/s \n",
            "\u001b[?25hCollecting fastapi==0.65.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b9/a91a699f5c201413b3f61405dbccc29ebe5ad25945230e9cec98fdb2434c/fastapi-0.65.1-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown==3.3.4 in /usr/local/lib/python3.7/dist-packages (from pycoder) (3.3.4)\n",
            "Collecting typer==0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n",
            "Collecting uvicorn==0.13.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/de/953f0289508b1b92debdf0a6822d9b88ffb0c6ad471d709cf639a2c8a176/uvicorn-0.13.4-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->pycoder) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->pycoder) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (3.0.12)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 52.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.1->pycoder) (4.0.1)\n",
            "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 50.1MB/s \n",
            "\u001b[?25hCollecting starlette==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/34/db1890f442a1cd3a2c761f4109a0eb4e63503218d70a8c8e97faa09a5500/starlette-0.14.2-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.1MB/s \n",
            "\u001b[?25hCollecting click<7.2.0,>=7.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.4MB/s \n",
            "\u001b[?25hCollecting h11>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.1->pycoder) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1->pycoder) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.1->pycoder) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.1->pycoder) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.1->pycoder) (3.4.1)\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pygments, click-spinner, huggingface-hub, tokenizers, click, sacremoses, transformers, pydantic, starlette, fastapi, typer, h11, uvicorn, pycoder\n",
            "  Found existing installation: Pygments 2.6.1\n",
            "    Uninstalling Pygments-2.6.1:\n",
            "      Successfully uninstalled Pygments-2.6.1\n",
            "  Found existing installation: click 8.0.0\n",
            "    Uninstalling click-8.0.0:\n",
            "      Successfully uninstalled click-8.0.0\n",
            "Successfully installed click-7.1.2 click-spinner-0.1.10 fastapi-0.65.1 h11-0.12.0 huggingface-hub-0.0.8 pycoder-1.0.2 pydantic-1.8.2 pygments-2.9.0 sacremoses-0.0.45 starlette-0.14.2 tokenizers-0.10.2 transformers-4.6.1 typer-0.3.2 uvicorn-0.13.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pygments"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaZ7FvSmUMGZ",
        "outputId": "4859cf71-bc2a-42a9-c475-43a151a17920"
      },
      "source": [
        "!pycoder --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 13:44:06.078700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Pycoder 🐍 CLI version: 1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHrly41SUX92",
        "outputId": "d16d7e8c-2ae6-4d43-a8fe-ddc2c5cc9ab2"
      },
      "source": [
        "!pycoder --help"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 13:44:13.234173: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Usage: pycoder [OPTIONS]\n",
            "\n",
            "  CLI command to get Python 🐍 code from set of\n",
            "  topic[s] and description. Examples:\n",
            "\n",
            "  🔥 pycoder --topic pytorch --description \"a\n",
            "  trainer for vision\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -d \"a trainer for vision\"\n",
            "\n",
            "  🔥 pycoder --topic pytorch --topic torch\n",
            "  --description \"a trainer for vision\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -t torch -d \"a trainer\n",
            "  for vision\"\n",
            "\n",
            "  🔥 pycoder --topic pytorch --topic torch\n",
            "  --description \"a trainer for vision\" --prefix\n",
            "  \"class Trainer:\"\n",
            "\n",
            "  🔥 pycoder -t pytorch -t torch -d \"a trainer\n",
            "  for vision\" --prefix \"class Trainer:\"\n",
            "\n",
            "Options:\n",
            "  -t, --topic TEXT                topic[s] for the\n",
            "                                  code to be\n",
            "                                  written.\n",
            "                                  [required]\n",
            "\n",
            "  -d, --description TEXT          description of\n",
            "                                  the code to be\n",
            "                                  written.\n",
            "                                  [required]\n",
            "\n",
            "  -p, --prefix TEXT               starting of the\n",
            "                                  code for pycoder\n",
            "                                  to follow.\n",
            "                                  [default: ]\n",
            "\n",
            "  -ml, --max-length INTEGER       max length of\n",
            "                                  code to\n",
            "                                  generate.\n",
            "                                  [default: 200]\n",
            "\n",
            "  -c, --cuda                      if cuda device\n",
            "                                  is to be used\n",
            "                                  for inference or\n",
            "                                  not. Might not\n",
            "                                  work in case\n",
            "                                  VRAM is <4GB.\n",
            "                                  [default: False]\n",
            "\n",
            "  -et, --execution_time           get execution\n",
            "                                  time of\n",
            "                                  generating the\n",
            "                                  code.  [default:\n",
            "                                  False]\n",
            "\n",
            "  -e, --endpoint                  specify the port\n",
            "                                  to start the\n",
            "                                  endpoint on.\n",
            "\n",
            "  -v, --version                   shows the\n",
            "                                  current version\n",
            "                                  of Pycoder.\n",
            "\n",
            "  --install-completion [bash|zsh|fish|powershell|pwsh]\n",
            "                                  Install\n",
            "                                  completion for\n",
            "                                  the specified\n",
            "                                  shell.\n",
            "\n",
            "  --show-completion [bash|zsh|fish|powershell|pwsh]\n",
            "                                  Show completion\n",
            "                                  for the\n",
            "                                  specified shell,\n",
            "                                  to copy it or\n",
            "                                  customize the\n",
            "                                  installation.\n",
            "\n",
            "  --help                          Show this\n",
            "                                  message and\n",
            "                                  exit.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNkDcialUap3",
        "outputId": "d9aad695-932f-4646-a25d-0951bfbc6bd6"
      },
      "source": [
        "!pycoder -t pytorch -t torch -d \"a trainer class to train vision model\" -ml 1024 -c -et"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 13:44:31.875696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "-\u001b[32m\n",
            "Model and Tokenizer being downloaded and saved from ModelHub (once only)...\n",
            "\u001b[0;0m\n",
            "Downloading: 100% 943/943 [00:00<00:00, 1.09MB/s]\n",
            "Downloading: 100% 1.44G/1.44G [00:23<00:00, 62.2MB/s]\n",
            "Downloading: 100% 943/943 [00:00<00:00, 1.13MB/s]\n",
            "Downloading: 100% 798k/798k [00:00<00:00, 2.47MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 1.38MB/s]\n",
            "Downloading: 100% 1.36M/1.36M [00:00<00:00, 3.49MB/s]\n",
            "Downloading: 100% 90.0/90.0 [00:00<00:00, 122kB/s]\n",
            "Downloading: 100% 120/120 [00:00<00:00, 150kB/s]\n",
            "Downloading: 100% 207/207 [00:00<00:00, 292kB/s]\n",
            "\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\u001b[32m\u001b[1m\n",
            "Model and Tokenizer saved. ✅\u001b[0;0m\n",
            "\n",
            "\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nn, optim\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m optim\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m preprocessing\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmanifold\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TSNE\n",
            "\n",
            "\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mevaluate\u001b[39;49;00m(dataset, model, criterion, optimizer, criterion_fn):\n",
            "    X = dataset[\u001b[33m'\u001b[39;49;00m\u001b[33mimages\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
            "    Y = dataset[\u001b[33m'\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
            "    label_list = [\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m4\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m, \u001b[34m6\u001b[39;49;00m]\n",
            "    \u001b[34mfor\u001b[39;49;00m idx, value \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(label_list):\n",
            "        X = X.to(\n",
            "            device=device, target_size=(\u001b[34m512\u001b[39;49;00m,), mode=\u001b[33m'\u001b[39;49;00m\u001b[33mbilinear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, depth=\u001b[34m0\u001b[39;49;00m, delta_value=\u001b[34m0\u001b[39;49;00m)\n",
            "        Y = Y.to(\n",
            "            device=device, target_size=(\u001b[34m128\u001b[39;49;00m,), mode=\u001b[33m'\u001b[39;49;00m\u001b[33mbilinear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, depth=\u001b[34m0\u001b[39;49;00m, delta_value=\u001b[34m0\u001b[39;49;00m)\n",
            "        model.zero_grad()\n",
            "\n",
            "        score = criterion(model(X), label_list, delta_value)\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mscore=\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mscore\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "\n",
            "        optimizer.zero_grad()\n",
            "        model.backward()\n",
            "\n",
            "        torch.save(model, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodels/Test_val\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "        score_val = score.detach().numpy()\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAccuracy=\u001b[39;49;00m\u001b[33m{accuracy:0.2f}\u001b[39;49;00m\u001b[33m, base=\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
            "\n",
            "\n",
            "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, X, y, loss, optimizer, criterion, train_loop, device, epoch):\n",
            "    model.train()\n",
            "    train_loss = \u001b[34m0\u001b[39;49;00m\n",
            "    \u001b[34mfor\u001b[39;49;00m idx, label \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loop):\n",
            "        \u001b[34mif\u001b[39;49;00m label \u001b[35min\u001b[39;49;00m y:\n",
            "            train_loss += loss\n",
            "        \u001b[34melif\u001b[39;49;00m label == -\u001b[34m1\u001b[39;49;00m:\n",
            "            model.zero_grad()\n",
            "\n",
            "    model.eval()\n",
            "\n",
            "    \u001b[34mreturn\u001b[39;49;00m torch.stack(model.nest(\u001b[34m1\u001b[39;49;00m, device = device, target_size = [\u001b[34m512\u001b[39;49;00m, \u001b[34m128\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m]))\n",
            "\n",
            "\n",
            "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
            "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m\n",
            "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\n",
            "    \n",
            "    model = nn.Sequential(\n",
            "        nn.Linear(\u001b[34m784\u001b[39;49;00m, \u001b[34m256\u001b[39;49;00m),\n",
            "        nn.GELU(),\n",
            "        nn.Linear(\u001b[34m256\u001b[39;49;00m, \u001b[34m300\u001b[39;49;00m),\n",
            "        nn.GELU(),\n",
            "        nn.Linear(\u001b[34m300\u001b[39;49;00m, \u001b[34m512\u001b[39;49;00m),\n",
            "        nn.GELU(),\n",
            "    )\n",
            "\n",
            "    num_classes = \u001b[34m20\u001b[39;49;00m\n",
            "    model = nn.Linear(\u001b[34m1\u001b[39;49;00m, num_classes)\n",
            "\n",
            "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, shape:\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, inputs: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model, (\u001b[34m1\u001b[39;49;00m,)))\n",
            "\n",
            "    train_model, train_loss = evaluate(model, test_val = [], evaluate_labels = [], evaluate_epoch = {}, epochs = \u001b[34m10\u001b[39;49;00m)\n",
            "\n",
            "    model.train()\n",
            "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mModel is \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, shape:\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, inputs: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model, (\u001b[34m1\u001b[39;49;00m,))\n",
            "\n",
            "    score = \u001b[34m0\u001b[39;49;00m\n",
            "    \u001b[34mfor\u001b[39;49;00m idx, target \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_loop):\n",
            "        target2 = y - target\n",
            "\n",
            "        \u001b[34mif\u001b[39;49;00m idx == \u001b[34m0\u001b[39;49;00m:\n",
            "            score = \u001b[34m0\u001b[39;49;00m\n",
            "        \u001b[34melif\u001b[39;49;00m idx == \u001b[34m1\u001b[39;49;00m:\n",
            "            score += loss(model, target, weight=\u001b[34m0\u001b[39;49;00m)\n",
            "        \u001b[34melse\u001b[39;49;00m:\n",
            "            score = \u001b[34m100\u001b[39;49;00m\n",
            "\n",
            "        score += \u001b[36mmax\u001b[39;49;00m(score, y.max())\n",
            "\n",
            "    \u001b[34mif\u001b[39;49;00m model.zero_grad():\n",
            "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mAccuracy(\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, idx, \u001b[33m\"\u001b[39;49;00m\u001b[33mbase=\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model,\n",
            "\n",
            "\u001b[32m\u001b[1mtook 67.84 seconds to code 😀\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBP_gDf8UfYG",
        "outputId": "4fc945e5-c5dd-4861-cb26-78ecd9f3d0bd"
      },
      "source": [
        "!pycoder -t pytorch -t vision -t mnist -d \"a mnist vision model and trainer. data downloaded from torchvision datasets. model with cnn layers. trainer class.\" -ml 1024 -c -et"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 13:48:38.944486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b|\b\\\b-\b/\b\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
            "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
            "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nn\n",
            "\n",
            "\n",
            "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDenseLayer\u001b[39;49;00m(nn.Module):\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_dim = \u001b[34m256\u001b[39;49;00m, layerDepth = \u001b[34m6\u001b[39;49;00m, output_dim = \u001b[34m512\u001b[39;49;00m):\n",
            "        superv = \u001b[34m1\u001b[39;49;00m\n",
            "        \u001b[36mself\u001b[39;49;00m.nLayer = nn.Linear(input_dim, layerDepth)\n",
            "        \u001b[34mif\u001b[39;49;00m layerDepth >\u001b[34m0\u001b[39;49;00m:\n",
            "            \u001b[36mself\u001b[39;49;00m.layerDepth = layerDepth\n",
            "        layers = (\u001b[36mself\u001b[39;49;00m.layerDepth // \u001b[34m2\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.layerDepth // \u001b[34m1\u001b[39;49;00m, \u001b[36mself\u001b[39;49;00m.layerDepth)\n",
            "\n",
            "\n",
            "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, images):\n",
            "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.layerDepth > \u001b[34m0\u001b[39;49;00m:\n",
            "            images = \u001b[36mself\u001b[39;49;00m.nLayer(images)\n",
            "        batch_size = images.shape[\u001b[34m0\u001b[39;49;00m]  \u001b[37m# images shape=[batch_size]\u001b[39;49;00m\n",
            "        height, width = images.shape[\u001b[34m1\u001b[39;49;00m]\n",
            "        \u001b[37m# xMin, xMax, yMin, yMax - uncertainty map\u001b[39;49;00m\n",
            "        xMin = (images[\u001b[34m0\u001b[39;49;00m].min() - images[\u001b[34m1\u001b[39;49;00m].min())\n",
            "        xMax = (images[\u001b[34m0\u001b[39;49;00m].max() - images[\u001b[34m1\u001b[39;49;00m].max())\n",
            "\n",
            "        \u001b[37m# xMin, xMax, yMin, yMax - uncertainty map\u001b[39;49;00m\n",
            "        xMin = (images[\u001b[34m0\u001b[39;49;00m].min() - images[\u001b[34m1\u001b[39;49;00m].min())\n",
            "        xMax = (images[\u001b[34m0\u001b[39;49;00m].max() - images[\u001b[34m1\u001b[39;49;00m].max())\n",
            "\n",
            "        nn.init.xavier_normal_(xMin, xMax)  \u001b[37m# psnr(xMin)\u001b[39;49;00m\n",
            "        nn.init.xavier_normal_(yMin, yMax)  \u001b[37m# psnr(yMin)\u001b[39;49;00m\n",
            "\n",
            "        \u001b[37m# xMin, xMax, yMin, yMax - uncertainty map\u001b[39;49;00m\n",
            "\n",
            "        images = np.flipud(imageData)  \u001b[37m# transpose(xMin, xMax)  # transpose(xMin, xMax, transpose(yMin, yMax))\u001b[39;49;00m\n",
            "\n",
            "        images = (images[\u001b[34m0\u001b[39;49;00m].min() - images[\u001b[34m1\u001b[39;49;00m].min())\n",
            "        images = np.flipud(np.flipud(images[\u001b[34m0\u001b[39;49;00m].min() + images[\u001b[34m1\u001b[39;49;00m].min()))  \u001b[37m# transpose(xMin, xMax, transpose(yMin, yMax))\u001b[39;49;00m\n",
            "\n",
            "        \u001b[37m# log_softmax(images)\u001b[39;49;00m\n",
            "        log_softmax = torch.exp(-log_softmax(images))\n",
            "\n",
            "        \u001b[34mreturn\u001b[39;49;00m images, log_softmax\n",
            "\n",
            "\n",
            "\u001b[37m#     def train_step():\u001b[39;49;00m\n",
            "        model = DenseLayer(data_dim=\u001b[34m16\u001b[39;49;00m,\n",
            "                              num_layers=\u001b[34m4\u001b[39;49;00m,\n",
            "                               layerDepth=\u001b[34m6\u001b[39;49;00m,\n",
            "                               loss=\u001b[33m'\u001b[39;49;00m\u001b[33mcategorical_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
            "                             )\n",
            "        model.train()  \u001b[37m# model.train()\u001b[39;49;00m\n",
            "\n",
            "\n",
            "\u001b[37m#     def train_step2():\u001b[39;49;00m\n",
            "        model = DenseLayer(data_dim=\u001b[34m16\u001b[39;49;00m,\n",
            "                              num_layers=\u001b[34m4\u001b[39;49;00m,\n",
            "                              layerDepth=\u001b[34m6\u001b[39;49;00m\n",
            "\n",
            "\u001b[32m\u001b[1mtook 25.54 seconds to code 😀\u001b[0;0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Q5YzCqVPZQ",
        "outputId": "9992caa1-4907-4a47-ed47-c1bdd21214fd"
      },
      "source": [
        "!pycoder -e"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-22 13:50:20.820782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m277\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m277\u001b[0m]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs_vW7c6V0lK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}